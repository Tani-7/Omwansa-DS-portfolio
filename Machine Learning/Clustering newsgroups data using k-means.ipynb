{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa514d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44a3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading, stemming and creating new data set\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "groups = fetch_20newsgroups(subset='all',categories=categories)\n",
    "\n",
    "labels = groups.target\n",
    "label_names = groups.target_names\n",
    "def is_letter_only(word):\n",
    "    for char in word:\n",
    "        if not char.isalpha():\n",
    "            return False\n",
    "        return True\n",
    "from nltk.corpus import names\n",
    "all_names = set(names.words())\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data_cleaned = []\n",
    "for doc in groups.data:\n",
    "    doc = doc.lower()\n",
    "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for\n",
    "        word in doc.split() if is_letter_only(word)\n",
    "        and word not in all_names)\n",
    "    data_cleaned.append(doc_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\",max_features=None, max_df=0.5, min_df=2)\n",
    "data = count_vector.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15fb7eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4, random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clustering\n",
    "from sklearn.cluster import KMeans\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f4f1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3365, 3: 12, 2: 7, 1: 3})\n"
     ]
    }
   ],
   "source": [
    "clusters = kmeans.labels_\n",
    "from collections import Counter\n",
    "print(Counter(clusters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5009e",
   "metadata": {},
   "source": [
    "count-based features are not sufficiently representative so  the better approach is to use a  frequency-inverse\n",
    "document frequency (tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e281504",
   "metadata": {},
   "source": [
    "##### replace CountVectorizer with TfidfVectorizer from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f43e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english',max_features=None, max_df=0.5, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c76305",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tfidf_vector.fit_transform(data_cleaned)\n",
    "kmeans.fit(data)\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5740922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 1580, 1: 1026, 2: 720, 0: 61})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcc10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_0: 61 samples\n",
      "sci.space: 61 samples\n",
      "Top 10 terms:\n",
      " dunn resembles svr3 work utzoo zoo spencer zoology toronto henry\n",
      "cluster_1: 1026 samples\n",
      "alt.atheism: 638 samples\n",
      "talk.religion.misc: 381 samples\n",
      "sci.space: 5 samples\n",
      "comp.graphics: 2 samples\n",
      "Top 10 terms:\n",
      " morality don sandvik jesus say christian people com wa god\n",
      "cluster_2: 720 samples\n",
      "sci.space: 700 samples\n",
      "comp.graphics: 10 samples\n",
      "talk.religion.misc: 7 samples\n",
      "alt.atheism: 3 samples\n",
      "Top 10 terms:\n",
      " launch moon alaska shuttle gov digex wa access nasa space\n",
      "cluster_3: 1580 samples\n",
      "comp.graphics: 961 samples\n",
      "talk.religion.misc: 240 samples\n",
      "sci.space: 221 samples\n",
      "alt.atheism: 158 samples\n",
      "Top 10 terms:\n",
      " know wa nntp host posting graphic file com image university\n"
     ]
    }
   ],
   "source": [
    "#\"\"\"Examining waht the  clusters contain and finding the top 10 terms \"\"\"\n",
    "\n",
    "cluster_label = {i: labels[np.where(clusters == i)] for i in range(k)}\n",
    "terms = tfidf_vector.get_feature_names()\n",
    "kmeans.fit(data)\n",
    "centroids = kmeans.cluster_centers_\n",
    "for cluster, index_list in cluster_label.items():\n",
    "        counter = Counter(cluster_label[cluster])\n",
    "        print('cluster_{}: {} samples'.format(cluster, len(index_list)))\n",
    "        for label_index, count in sorted(counter.items(),key=lambda x: x[1], reverse=True):\n",
    "            print('{}: {} samples'.format(label_names[label_index], count))\n",
    "        print('Top 10 terms:')\n",
    "        for ind in centroids[cluster].argsort()[-10:]:\n",
    "            print(' %s' % terms[ind], end=\"\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbcbea",
   "metadata": {},
   "source": [
    "#### Topic modeling using NMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfa7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "t = 20\n",
    "nmf = NMF(n_components=t, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21efbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = count_vector.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c9ae8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=20, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af23fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05199448, 0.        , 0.00016396, ..., 0.        , 0.        ,\n",
       "        0.00066426],\n",
       "       [0.00028246, 0.        , 0.00103722, ..., 0.        , 0.00046909,\n",
       "        0.00136239],\n",
       "       [0.        , 0.        , 0.00016499, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00315889, 0.        , 0.01103702, ..., 0.00100776, 0.00735967,\n",
       "        0.00162324],\n",
       "       [0.        , 0.        , 0.00024811, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00456599, ..., 0.        , 0.00022907,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acb0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bef7af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "free program quality version format color gif file image jpeg\n",
      "Topic 1:\n",
      "graphics image server ftp pub file send graphic ray mail\n",
      "Topic 2:\n",
      "doe christian people believe belief religious religion atheism god atheist\n",
      "Topic 3:\n",
      "wa venus atmosphere sun surface moon solar spacecraft earth planet\n",
      "Topic 4:\n",
      "program include ha user software analysis processing data tool image\n",
      "Topic 5:\n",
      "shall wa said son unto christ mcconkie father lord god\n",
      "Topic 6:\n",
      "data venture service year ha market commercial space satellite launch\n",
      "Topic 7:\n",
      "day christian psalm people said prophecy ha wa matthew jesus\n",
      "Topic 8:\n",
      "program software format ha sgi package ftp available image data\n",
      "Topic 9:\n",
      "unified space motion book star physicist physical universe theory larson\n",
      "Topic 10:\n",
      "research sci group international national telescope satellite shuttle list space\n",
      "Topic 11:\n",
      "jpl available mission astronaut shuttle center data gov space nasa\n",
      "Topic 12:\n",
      "year magi new zarathushtra war book did time people wa\n",
      "Topic 13:\n",
      "form ha false ad premise true example conclusion fallacy argument\n",
      "Topic 14:\n",
      "isbn information file data siggraph format graphics image ftp available\n",
      "Topic 15:\n",
      "say db greek reply mr hanging act wa matthew juda\n",
      "Topic 16:\n",
      "veronica server data ftp information software database client search gopher\n",
      "Topic 17:\n",
      "moral make know com like say just people think don\n",
      "Topic 18:\n",
      "know believe doe christian christ child jesus bible ra god\n",
      "Topic 19:\n",
      "kilometer earth planet surface space soviet mission venus probe wa\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic {}:\" .format(topic_idx))\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[-10:]]))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e18b9",
   "metadata": {},
   "source": [
    "#### Topic modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d629d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb1e1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eefeff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=t, learning_method='batch',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f2f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = count_vector.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cb18682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=20, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "258c11ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.78477238, 0.05      , 0.05      , ..., 0.05      , 0.05      ,\n",
       "        0.05      ],\n",
       "       [0.05      , 0.05      , 1.24460302, ..., 0.05      , 0.05      ,\n",
       "        0.05      ],\n",
       "       [0.05      , 0.05      , 0.3395871 , ..., 0.05      , 0.05      ,\n",
       "        0.05      ],\n",
       "       ...,\n",
       "       [0.05000002, 0.05      , 0.05      , ..., 0.05      , 0.05      ,\n",
       "        0.05      ],\n",
       "       [0.05      , 0.05      , 0.05      , ..., 0.05      , 0.05      ,\n",
       "        0.05      ],\n",
       "       [0.05      , 0.05      , 1.02314724, ..., 0.05      , 0.05      ,\n",
       "        0.05      ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d80c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "say uk know ha life matthew just brian wa jesus\n",
      "Topic 1:\n",
      "oort nntp host distribution search know posting just gopher gamma\n",
      "Topic 2:\n",
      "conference nntp posting cost host year space wa digex access\n",
      "Topic 3:\n",
      "graphic software available ftp data program format jpeg file image\n",
      "Topic 4:\n",
      "computer help looking graphic know thanks posting university nntp host\n",
      "Topic 5:\n",
      "point host nntp posting solntze wpd livesey sgi com wa\n",
      "Topic 6:\n",
      "atheist doe morality moral religion think don god say people\n",
      "Topic 7:\n",
      "host know lis posting wa space university uiuc god cobb\n",
      "Topic 8:\n",
      "science send national cs center mail sci gov nasa space\n",
      "Topic 9:\n",
      "time people think like keith caltech just wa don com\n",
      "Topic 10:\n",
      "book ray star god wa energy physical larson universe theory\n",
      "Topic 11:\n",
      "don say jesus ha people know christian bible wa god\n",
      "Topic 12:\n",
      "wa ha zoology zoo satellite space spencer launch toronto henry\n",
      "Topic 13:\n",
      "rushdie shall ha christ people lord jesus law god wa\n",
      "Topic 14:\n",
      "know host nntp people posting just don okcforum polygon wa\n",
      "Topic 15:\n",
      "wa ca uci kelvin gif jsc baalke jpl gov nasa\n",
      "Topic 16:\n",
      "wa net activity private kent wrote newton apple sandvik com\n",
      "Topic 17:\n",
      "time posting moon just station nasa com wa alaska space\n",
      "Topic 18:\n",
      "nntp host timmons thing cacs fraering pgf usl com like\n",
      "Topic 19:\n",
      "hst solar nasa planet moon wa space earth mission orbit\n"
     ]
    }
   ],
   "source": [
    "terms = count_vector.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic {}:\" .format(topic_idx))\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
